## BeesRStan.R
## some useful small functions

jitter.binary <- function(a, jitt=.05, up=1){
    ## for plotting logistic regression model
    up*(a + (1-2*a)*runif(length(a),0,jitt))
}

to2 <- function(x){
    ## conver a single digit integer to 0x
    return(ifelse (x<10, paste("0",x, sep=""), as.character(x)))
}

to3 <-
    function(x){
        ## conver a single or double digit integer to 0x or 00x
        n <- length(x)
        temp <- character()
        for (i in 1:n){
            if(x[i] < 10) temp[i] <- paste("00",x[i], sep="")
            else if(x[i]<100) temp[i] <- paste("0",x[i], sep="")
            else temp[i] <- x[i]
        }
        return(temp)
    }

invlogit <- function(x) return(1/(1+exp(-x)))

standardize <- function(x)return((x-mean(x, na.rm=T))/sd(x, na.rm=T))

ini <- function(mat, val) {                         # Initializing matrices
    ina <- is.na(mat); mat[ina] <- val; mat[!ina] <- NA; mat;}

binned.resids <- function (x, y, nclass=sqrt(length(x))){
    breaks.index <- floor(length(x)*(1:(nclass-1))/nclass)
    breaks <- c (-Inf, sort(x)[breaks.index], Inf)
    output <- NULL
    xbreaks <- NULL
    x.binned <- as.numeric (cut (x, breaks))
    for (i in 1:nclass){
        items <- (1:length(x))[x.binned==i]
        x.range <- range(x[items])
        xbar <- mean(x[items])
        ybar <- mean(y[items])
        n <- length(items)
        sdev <- sd(y[items])
        output <- rbind (output, c(xbar, ybar, n, x.range, 2*sdev/sqrt(n)))
    }
    colnames (output) <- c ("xbar", "ybar", "n", "x.lo", "x.hi", "2se")
    return (list (binned=output, xbreaks=xbreaks))
}

binned.cali <- function(x, y, from=0, to=1, nclass=11, full=TRUE){
    if (!full) to <- min(c(1, max(x)))
    breaks <- seq(from=from, to=to, ,nclass)
    output <- NULL
    xbreaks <- NULL
    x.binned <- as.numeric (cut (x, breaks))
    for (i in 1:nclass){
        items <- (1:length(x))[x.binned==i]
        x.range <- range(x[items])
        xbar <- mean(x[items])
        ybar <- mean(y[items])
        n <- length(items)
        output <- rbind (output, c(xbar, ybar, n, x.range))
    }
    colnames (output) <- c ("xbar", "ybar", "n", "x.lo", "x.hi")
    return (list (binned=output, xbreaks=xbreaks))
}


summary.plot <- function(bugs.out, rows, ylabel = NULL, Xlim=NULL, xlab="values", ylab=" ", Mean=T, color=T, yaxis=2, ...){
    ##
    ## Generates ANOVA-like plots from bugs output
    ## 'bugs.out' is generated by function 'bugs' from linrary(R2WinBUGS)
    ##
    Plot.data <- bugs.out$summary[rows,]
    plotting.region <- range(c(Xlim,Plot.data[,c(3,7)]))
                                        #    par(mar=c(5,ymar,1,1), mgp=c(1.5,0.5,0))
    plot(seq(plotting.region[1], plotting.region[2],,length(rows)),
         seq(0.5,length(rows)+0.5,,length(rows)), type="n",
         xlab=xlab, ylab=ylab, axes=F, ...)
    axis(1)
    if (is.null(ylabel))
        axis(yaxis, at=1:length(rows), labels=row.names(Plot.data),
             padj=0.5, las=1, ...)
    else axis(yaxis, at=1:length(rows), labels=ylabel, padj=0.5,
              las=1, ...)
    if (color){
        segments(x0=Plot.data[,3], x1=Plot.data[,7],
                 y0=1:length(rows), y1=1:length(rows))
        segments(x0=Plot.data[,4], x1=Plot.data[,6],
                 y0=1:length(rows), y1=1:length(rows), lwd=3)
        abline(v=0, col=8)
        if(Mean) points(Plot.data[,1], 1:length(rows))
        else points(Plot.data[,5], 1:length(rows))
    } else {
        segments(x0=Plot.data[,3], x1=Plot.data[,7],
                 y0=1:length(rows), y1=1:length(rows))
        segments(x0=Plot.data[,4], x1=Plot.data[,6],
                 y0=1:length(rows), y1=1:length(rows), lwd=3, col="gray4")
        abline(v=0, col="gray")
        if(Mean) points(Plot.data[,1], 1:length(rows), cex=1.125)
        else points(Plot.data[,5], 1:length(rows), cex=1.125)
    }
    invisible()
    }


summary.plot.BRugs <- function(summary.from.bugs, ylab = NULL,
                               xlab="values", ymar=7, ...){
##
    ## Generates ANOVA-like plots from bugs output
    ## 'summary.from.bugs' is a rbind matrix, each row represents a parameter
    ##
    Plot.data <- t(apply(summary.from.bugs, 1,
                         FUN=function(x)
                         return(c(mean(x),
                quantile(x, prob=c(0.025, 0.25, 0.5, 0.75, 0.975))))))
    plotting.region <- range(Plot.data)
    n<-dim(summary.from.bugs)[1]
    par(mar=c(3.5,ymar,1,1), mgp=c(1.5,0.5,0))
    plot(seq(plotting.region[1], plotting.region[2],,n),
         seq(0.5,n+0.5,,n), type="n", xlab=xlab, ylab=" ", axes=F, ...)
    axis(1)
    if (is.null(ylab))
        axis(2, at=1:n, labels=row.names(Plot.data), padj=1, las=1, ...)
    else axis(2, at=1:n, labels=ylab, padj=1, las=1)
    segments(x0=Plot.data[,2], x1=Plot.data[,6], y0=1:n, y1=1:n, col=3)
    segments(x0=Plot.data[,3], x1=Plot.data[,5], y0=1:n, y1=1:n, lwd=3,
             col=4)
    abline(v=0, col=8)
    points(Plot.data[,1], 1:n, col='red')
    invisible(Plot.data)
    }


logit<-
    function (p, percents = max(p, na.rm = TRUE) > 1, adjust)
{
    if (percents)
        p <- p/100
    a <- if (missing(adjust)) {
        if (min(p, na.rm = TRUE) == 0 | max(p, na.rm = TRUE) ==
            1)
            0.025
        else 0
    }
    else adjust
    if (missing(adjust) & a != 0)
        warning(paste("Proportions remapped to (", a, ",", 1 -
                      a, ")", sep = ""))
    a <- 1 - 2 * a
    log((0.5 + a * (p - 0.5))/(1 - (0.5 + a * (p - 0.5))))
}

lm.plots <- function(lm.obj){
    obj1<-xyplot(fitted(lm.obj)~(fitted(lm.obj)+resid(lm.obj)),
                 panel = function(x, y,...) {
                     panel.xyplot(x, y,...)
                     panel.abline(0,1, col="red",...)
                     panel.loess(x,y, span=1.0,col="green",...)
                     panel.grid()
                 },ylab="Fitted",xlab="Observed")
    ## checking whether the predicted is in greement with the observed

    obj2<-qqmath(~resid(lm.obj),
                 panel = function(x,...) {
                     panel.grid()
                     panel.qqmath(x,...)
                     panel.qqmathline(x,...)
                 }, ylab="Residuals", xlab="Standard Normal Quantile"
                 )
    ## checking whether residuals are normally distributed

    obj3<-xyplot(resid(lm.obj)~fitted(lm.obj), panel=function(x,y,...){
        panel.grid()
        panel.xyplot(x, y,...)
        panel.abline(0, 0)
        panel.loess(x, y, span=1, col=2,...)
    }, ylab="Residuals", xlab="Fitted")
    ## checking for patterns in residuals (independence)

    obj4<-xyplot(sqrt(abs(resid(lm.obj)))~fitted(lm.obj), panel=function(x,y,...){
        panel.grid()
        panel.xyplot(x, y,...)
        panel.loess(x, y, span=1, col=2,...)
    }, ylab="Sqrt. Abs. Residuals", xlab="Fitted")
    ## checking whether the residuals have a constant variance

    obj5<-rfs(lm.obj, aspect=1)
    ## visualizing R^2

    obj6 <- xyplot(cooks.distance(lm.obj) ~ fitted(lm.obj),
                   panel=function(x,y,...){
                       panel.xyplot(x,y,...)
                       panel.grid()},
                   ylab="Cook's Distance", xlab="Fitted")
    ## checking for influential data points

    print(obj1, position = c(0.0, 0.0, 0.5, 1/3), more = T)
    print(obj2, position = c(0.5, 0.0, 1.0, 1/3), more = T)
    print(obj3, position = c(0.0, 1/3, 0.5, 2/3), more = T)
    print(obj4, position = c(0.5, 1/3, 1.0, 2/3), more = T)
    print(obj5, position = c(0.0, 2/3, 0.5, 1.0), more = T)
    print(obj6, position = c(0.5, 2/3, 1.0, 1.0), more = F)
    invisible()
}

summary.plot.Interaction<-
    function(bugs.out=bugs.out.S, rows, ylab = NULL, xlab=" ",
             treatment, block, reverse=F, ymar=7, ...){
        ##
        ## Graphical presentation of interaction effect from bugs output
        ## 'bugs.out' is generated by function 'bugs' from linrary(R2WinBUGS)
##
        Plot.data <- bugs.out$summary[rows,]
        plotting.region <- range(Plot.data[,c(3,7)])
                                        #    treatment  <- levels(seaweed$TREAT)
        nt <- length(treatment)
                                        #    block <- paste("Block", 1:8)
        nb <- length(block)
        if(reverse){
            par(mfrow=c(1, nt), oma=c(0.5,ymar,1,1), mar=c(5, 0, 0, 0))
            for (i in 1:nt){
                plot(seq(plotting.region[1], plotting.region[2],,5),
                     seq(1-0.1, nb+.1, ,5), type="n",
                     xlab=treatment[i], ylab=" ", axes=F, ...)
                axis(1)
                if (i==1)
                    axis(2, at=1:nb, labels=block, las=1, outer=T, ...)
                segments(x0=Plot.data[((i-1)*nb+1):(i*nb),3],
                         x1=Plot.data[((i-1)*nb+1):(i*nb),7],
                         y0=1:nb, y1=1:nb)
                segments(x0=Plot.data[((i-1)*nb+1):(i*nb),4],
                         x1=Plot.data[((i-1)*nb+1):(i*nb),6],
                         y0=1:nb, y1=1:nb, lwd=3)
                abline(v=0, col="gray")
                points(Plot.data[((i-1)*nb+1):(i*nb),1], 1:nb)
            }
        } else {
            par(mfrow=c(1, nb), oma=c(5,7,4,4), mar=c(3.5, 0, 0, 0))
            for (i in 1:nb){
                plot(seq(plotting.region[1], plotting.region[2],,5),
                     seq(1-0.1, nt+.1, ,5), type="n",
                     xlab=block[i], ylab=" ", axes=F)
                axis(1)
                if (i==1)
                    axis(2, at=1:nt, labels=treatment, las=1, outer=T)
                segments(x0=Plot.data[seq(i,nt*nb,nb),3],
                         x1=Plot.data[seq(i,nt*nb,nb),7],
                         y0=1:nt, y1=1:nt)
                segments(x0=Plot.data[seq(i,nt*nb,nb),4],
                         x1=Plot.data[seq(i,nt*nb,nb),6],
                         y0=1:nt, y1=1:nt, lwd=3)
                abline(v=0, col="gray")
                points(Plot.data[seq(i,nt*nb,nb),1], 1:nt)
            }
        }
        mtext("Interaction Effects", side=1, outer=T, line=-2.5)
        invisible()
    }

##display lmer ranefs

plot.lmer.ranef<-function(M, column=1, xlab="Intercept", ylab="Group",
                          ranV=1, yaxis=2, y.cex=1, column.fixed=1,
                          oo=NULL, oo2=NULL, effect=TRUE, ylabel=NULL){
    if (is.null(oo)) oo <- 1:dim(ranef(M)[[ranV]])[1]
    n <- length(oo)
    if (is.null(oo2)) oo2 <- order(ranef(M)[[ranV]][oo,column])
    else if (length(oo2)==1) oo2 <- 1:n
    if (effect) {
        mn <- ranef(M)[[ranV]][oo,column]
    } else {
        mn <- ranef(M)[[ranV]][oo,column] + fixef(M)[column]
    }
    se.mn <- se.ranef(M)[[ranV]][oo,column]
    plot(c(0,1),c(0,1), type="n", xlim=range(c(mn+2*se.mn, mn-2*se.mn)),
         ylim=c(1, n), xlab=xlab, ylab=ylab, axes=F)
    segments(x0=mn[oo2]-2*se.mn[oo2], x1=mn[oo2]+2*se.mn[oo2],
             y0=1:n, y1=1:n)
    segments(x0=mn[oo2]-1*se.mn[oo2], x1=mn[oo2]+1*se.mn[oo2],
             y0=1:n, y1=1:n, lwd=2)
    abline(v=0, col="gray")
    points(x=mn[oo2], y=1:n)
    axis(1, cex.axis=y.cex)
    if (is.null(ylabel)) ylabel <- row.names(ranef(M)[[ranV]])[oo]
    if (!is.null(yaxis)) axis(yaxis, at=1:n, label=ylabel[oo2],
                              las=1, cex.axis=y.cex, lwd=0.5)
    title(main=round(fixef(M)[column.fixed], 3), cex=0.5)
    invisible()
}

hockey <- function(x,beta0,beta1,beta2,brk,eps=diff(range(x))/100,
                   delta=T) {
       ## alpha1 is the intercept of the left line segment
       ## beta1 is the slope of the left line segment
       ## beta2 is the slope of the right line segment
       ## brk is location of the break point
       ## 2*eps is the length of the connecting quadratic piece

       ## reference: Bacon & Watts "Estimating the Transition Between
       ## Two Intersecting Straight Lines", Biometrika, 1971
        x <- x-brk
        if (delta) beta2 <- beta1+beta2
##        x1 <- -eps
##        x2 <- +eps
        b <- (beta1+beta2)/2 ##(x2*beta1-x1*beta2)/(x2-x1)
        cc <- (beta2-beta1)/(4*eps) ##(beta2-b)/(2*x2)
        a <- beta0+(beta2-beta1)*eps/4 ##alpha1+beta1*x1-b*x1-cc*x1^2
##        alpha2 <- - beta2*x2 +(a + b*x2 + cc*x2^2)

        lebrk <- (x <= -eps)
        gebrk <- (x >= eps)
        eqbrk <- (x > -eps & x < eps)
        result <- rep(0,length(x))
        result[lebrk] <- beta0 + beta1*x[lebrk]
        result[eqbrk] <- a + b*x[eqbrk] + cc*x[eqbrk]^2
        result[gebrk] <- beta0 + beta2*x[gebrk]
        result
}

sim.nls <- function (object, n.sims=100){
# sim.nls:  get posterior simulations of sigma and beta from a nls object
#
# Arguments:
#
#     object:  the output of a call to "nls"
#              with n data points and k predictors
#     n.sims:  number of independent simulation draws to create
#
# Output is a list (sigma.sim, beta.sim):
#
#     sigma.sim:  vector of n.sims random draws of sigma
#       (for glm's, this just returns a vector of 1's or else of the
#       square root of the overdispersion parameter if that is in the model)
#     beta.sim:  matrix (dimensions n.sims x k) of n.sims random draws of beta
#

  object.class <- class(object)[[1]]
  if (object.class!="nls") stop("not a nls object")

    summ <- summary (object)
    coef <- summ$coef[,1:2,drop=FALSE]
    dimnames(coef)[[2]] <- c("coef.est","coef.sd")
    sigma.hat <- summ$sigma
    beta.hat <- coef[,1]
    V.beta <- summ$cov.unscaled
    n <- summ$df[1] + summ$df[2]
    k <- summ$df[1]
    sigma <- rep (NA, n.sims)
    beta <- array (NA, c(n.sims,k))
    dimnames(beta) <- list (NULL, names(beta.hat))
    for (s in 1:n.sims){
      sigma[s] <- sigma.hat*sqrt((n-k)/rchisq(1,n-k))
      beta[s,] <- mvrnorm (1, beta.hat, V.beta*sigma[s]^2)
    }
    return (list (beta=beta, sigma=sigma))
  }

## Two probability distributions
two.prob<- function(mux=1, vx=1, alpha=2.5, gamma=0.5){
  par(mfrow=c(2,1))
  plot(seq(0,20,,100), dlnorm(seq(0,20,,100), mux, sqrt(vx)),
       type="l", xlab="Log Normal X", ylab="")
  usr <- par("usr")
  abline(v=exp(mux+vx/2),col=5)
  s2 <- (exp(vx-1))*exp(2*mux+vx)
  mn <- exp(mux+vx/2)
  text.x <- usr[1] + 0.75*(usr[2]-usr[1])
  text.y <- usr[3] + 0.5*(usr[4]-usr[3])
  text(x=text.x, y=text.y,
       bquote(paste(mu," = ", .(round(mn, digit=2)), ", ",
                    sigma," = ", .(round(sqrt(s2), digit=2)))))
  plot(seq(0,20,,100), dgamma(seq(0,20,,100), alpha, gamma),
       type="l", xlab="Gamma X", ylab="")
  abline(v=alpha/gamma, col=5)
  s2 <- alpha/gamma^2
  mn <- alpha/gamma
  usr <- par("usr")
  text.x <- usr[1] + 0.75*(usr[2]-usr[1])
  text.y <- usr[3] + 0.5*(usr[4]-usr[3])
  text(x=text.x, y=text.y,
       bquote(paste(mu," = ", .(round(mn, digit=2)), ", ",
                    sigma," = ", .(round(sqrt(s2), digit=2)))))
  invisible()
}


## simulation for illustrating the central limit theorem
central.sim <- function(mux=1.5, vx=2, alpha=2.5, gamma=0.5, n=c(10, 50, 100)){
  X.ln <- X.gm <- numeric()
  par(mfcol=c(2,3), mar=c(2.5,.75,2.5,0.25), mgp=c(1.5, 0.5, 0))
  for (k in n){
    for (i in 1:10000){
      X.ln[i] <- mean(rlnorm(k, mux, sqrt(vx)))
      X.gm[i] <- mean(rgamma(k, alpha, gamma))
    }
    hist(X.ln, prob=T, xlim=c(0,20), ylim=c(0, 0.7),
         main=paste("N = ", k, sep=""),
         xlab="Log-Normal X", ylab="", axes=F)
    axis(1)
    lines(seq(0,20,,1000), dlnorm(seq(0,20,,1000), mux, sqrt(vx)))
    abline(v=exp(mux+vx/2), col="grey")
    s2 <- (exp(vx-1))*exp(2*mux+vx)
    mn <- exp(mux+vx/2)
    usr <- par("usr")
    text.x <- usr[1] + 0.65*(usr[2]-usr[1])
    text.y <- usr[3] + 0.5*(usr[4]-usr[3])
    text(x=text.x, y=text.y,
         bquote(paste(hat(mu)," = ", .(round(mean(X.ln), digit=2)), ", ",
                      hat(sigma)," = ", .(round(sd(X.ln), digit=2)))),
         cex=0.85)
    text.y <- usr[3] + 0.25*(usr[4]-usr[3])
    text(x=text.x, y=text.y,
         bquote(paste(mu," = ", .(round(mn, digit=2)), ", ",
                      sigma," = ", .(round(sqrt(s2/k), digit=2)))),
         cex=0.85)
    hist(X.gm, prob=T, nclass=20, xlim=c(0,20), main=paste("N = ", k, sep=""),
         xlab="Gamma X", ylab="", ylim=c(0, 1.2), axes=F)
    axis(1)
    lines(seq(0,20,,100), dgamma(seq(0, 20,,100), alpha, gamma))
    abline(v=alpha/gamma, col="grey")
    s2 <- alpha/gamma^2
    mn <- alpha/gamma
        usr <- par("usr")
    text.x <- usr[1] + 0.65*(usr[2]-usr[1])
    text.y <- usr[3] + 0.5*(usr[4]-usr[3])
    text(x=text.x, y=text.y,
         bquote(paste(hat(mu)," = ", .(round(mean(X.gm), digit=2)), ", ",
                      hat(sigma)," = ", .(round(sd(X.gm), digit=2)))),
         cex=0.85)
    text.y <- usr[3] + 0.25*(usr[4]-usr[3])
    text(x=text.x, y=text.y, bquote(paste(mu," = ", .(round(mn, digit=2)), ", ",
                     sigma," = ", .(round(sqrt(s2/k), digit=2)))), cex=0.85)
  }
}


### Distribution-free tests
hypo.sim <- function(n.sims, rdistF, theta, ...){
  reject.t1<-0;reject.t2<-0;reject.w1<-0;reject.w2<-0
  for (i in 1:n.sims){
    u <- rdistF(20, ...)
    y<-u
    for (j in 2:20)
      y[j] <- u[j] - theta*u[j-1]
    samp1 <- data.frame(x=y, g=sample(1:2, 20, TRUE))
### randomized sample
    samp2 <- data.frame(x=y, g=rep(c(1,2), each=10))
### correlated sample
    reject.t1 <- reject.t1 +
      (t.test(x~g, data=samp1, var.equal=T)$p.value<0.05)
    reject.t2 <- reject.t2 +
      (t.test(x~g, data=samp2, var.equal=T)$p.value<0.05)
    reject.w1 <- reject.w1 +
      (wilcox.exact(x~g, data=samp1)$p.value<0.05)
    reject.w2 <- reject.w2 +
      (wilcox.exact(x~g, data=samp2)$p.value<0.05)
  }
  return(rbind(c(reject.t2,reject.t1),
               c(reject.w2,reject.w1))/n.sims)
}


## median polish
median.polish.ts <- function(data.ts, ylab="", plt=T){
# median polishing for missing value imputation
medpolish(matrix(data.ts, ncol=12, byrow=T), eps=0.001, na.rm=T)->temp.2w
print(names(temp.2w))
year.temp <- rep(seq(start(data.ts)[1], end(data.ts)[1]), each=12)
month.temp <- rep(1:12, length(seq(start(data.ts)[1], end(data.ts)[1])))
# plotting median polishing results
if (plt){
  par(mfrow=c(2,1))
  plot(seq(start(data.ts)[1], end(data.ts)[1]),
       temp.2w$overall+temp.2w$row, type="l",
       xlab="Year", ylab=ylab, main="De-seasonalized Trend")
  plot(seq(1,12), temp.2w$overall+temp.2w$col, type="l",
       xlab="Month", ylab=ylab, main="Seasonal Changes")
}
data.ts[is.na(data.ts)]<-temp.2w$overall +
  temp.2w$row[year.temp[is.na(data.ts)]-start(data.ts)[1]+1]+
    temp.2w$col[month.temp[is.na(data.ts)]]
invisible(data.ts)
}
#### end of median polishing for missing value imputation


stl.rfs <-
function(data = carbon.dioxide, ss.w = 25, ss.d = 1, fc.w = 120, fc.d = 1, ylab = "Carbon Dioxide (ppm)", aspect = "xy", ...)
{
 strip.background <- trellis.par.get("strip.background")
 strip.background$col <- 0.
 trellis.par.set("strip.background", strip.background)
 strip.shingle <- trellis.par.get("strip.shingle")
 strip.shingle$col <- 0.
 trellis.par.set("strip.shingle", strip.shingle)
    the.fit <- stl(data, s.window = ss.w, s.degree = ss.d, t.window = fc.w, t.degree = fc.d, ...)
    sfit <- the.fit$time.series[,1]
    tfit <- the.fit$time.series[,2]
    fit.time <- time(data)
    car.subseries <- factor(cycle(data), label = month.abb)

    obj1 <- xyplot(sfit ~ fit.time | car.subseries, layout = c(12, 1), panel = function(x, y)
    {
        panel.xyplot(x, y, type = "l")
        panel.abline(h = mean(y))
    }
    , aspect = aspect, xlab = "Year", ylab = ylab)

    obj2 <- xyplot(tfit ~ fit.time, panel = function(x, y)
    panel.xyplot(x, y, type = "l"), xlab = "", aspect = "xy", ylab = "")

    n <- length(data)
    the.fit.trend <- the.fit$time.series[,2] - mean(the.fit$time.series[,2])
    fit.components <- c(the.fit.trend, the.fit$time.series[,1], the.fit$time.series[,3])
    fit.time <- rep(time(data), 3)
    fit.names <- ordered(rep(c("Trend", "Seasonality", "Residuals"), c(n, n, n)), c("Trend",
        "Seasonality", "Residuals"))

    obj3 <- xyplot(fit.components ~ fit.time | fit.names, panel = function(x, y)
    {
        panel.grid(h = 5)
        panel.xyplot(x, y, type = "l")
    }
    , aspect=0.75, layout = c(3, 1), ylim = c(-1, 1) * max(abs(fit.components)), xlab = "", ylab = ylab)
    print(obj1, position = c(0, 0, 1, 0.4), more = T)
    print(obj2, position = c(0, 0.33, 1, 0.67), more = T)
    print(obj3, position = c(0, 0.6, 1, 1), more = F)
    invisible(data.frame(trend=the.fit$time.series[,2], season=the.fit$time.series[,1], residual=the.fit$time.series[,3]))
}


stl.rfs2 <-
function(data = carbon.dioxide, ss.w = 25, ss.d = 1, fc.w = 120, fc.d = 1, ylab = "Carbon Dioxide (ppm)", aspect = "xy", ...)
{
 strip.background <- trellis.par.get("strip.background")
 strip.background$col <- 0.
 trellis.par.set("strip.background", strip.background)
 strip.shingle <- trellis.par.get("strip.shingle")
 strip.shingle$col <- 0.
 trellis.par.set("strip.shingle", strip.shingle)
    the.fit <- stl(data, s.window = ss.w, s.degree = ss.d, t.window = fc.w, t.degree = fc.d, ...)
    sfit <- the.fit$time.series[,1]
    tfit <- the.fit$time.series[,2]
    fit.time <- time(data)
    car.subseries <- factor(cycle(data), label = month.abb)

    obj1 <- xyplot(sfit ~ fit.time | car.subseries, layout = c(12, 1), panel = function(x, y)
    {
        panel.xyplot(x, y, type = "l")
        panel.abline(h = mean(y))
    }
    , aspect = aspect, xlab = "Year", ylab = ylab)

    obj2 <- xyplot(tfit ~ fit.time, panel = function(x, y)
    panel.xyplot(x, y, type = "l"), xlab = "", aspect = "xy", ylab = "")

    n <- length(data)
    the.fit.trend <- the.fit$time.series[,2] - mean(the.fit$time.series[,2])
    fit.components <- c(the.fit.trend, the.fit$time.series[,1], the.fit$time.series[,3])
    fit.time <- rep(time(data), 3)
    fit.names <- ordered(rep(c("Trend", "Seasonality", "Residuals"), c(n, n, n)), c("Trend",
        "Seasonality", "Residuals"))

    obj3 <- xyplot(fit.components ~ fit.time | fit.names, panel = function(x, y)
    {
        panel.grid(h = 5)
        panel.xyplot(x, y, type = "l")
    }
    , aspect=0.75, layout = c(3, 1), ylim = c(-1, 1) * max(abs(fit.components)), xlab = "", ylab = ylab)
    print(obj1, position = c(0, 0, 1, 0.6), more = T)
    print(obj3, position = c(0, 0.4, 1, 1), more = F)
    invisible(data.frame(trend=the.fit$time.series[,2], season=the.fit$time.series[,1], residual=the.fit$time.series[,3]))
}


## the changepoint program for normal response:
chngp.nonpar <- function(infile)
{
    temp <- na.omit(infile)
    yy <- temp$Y
    xx <- temp$X
    mx <- sort(unique(xx))
    m <- length(mx)
    vi <- numeric()
    vi [m] <- sum((yy - mean(yy))^2)
    for(i in 1:(m-1))
            vi[i] <- sum((yy[xx <= mx[i]] - mean(yy[xx <=
                mx[i]]))^2) + sum((yy[xx > mx[i]] - mean(
                yy[xx > mx[i]]))^2)
    chngp <- mean(mx[vi == min(vi)])
    return(chngp)
}

my.bootCIs<-
function (x, nboot, theta, ..., alpha = c(0.05, 0.95))
{ # calculating confidence interval using both percentiles and the BCa method
  # modified from Efron's function 'bacnon'
    n <- length(x)
    thetahat <- theta(x, ...)
    bootsam <- matrix(sample(x, size = n * nboot, replace = TRUE),
        nrow = nboot)
    thetastar <- apply(bootsam, 1, theta, ...)
    confpoints.percent <- quantile(thetastar, alpha)
    if (sum(thetastar < thetahat)==0) return(rep(as.vector(confpoints.percent), 2))
    else {
    z0 <- qnorm(sum(thetastar < thetahat)/nboot)
        u <- rep(0, n)
        for (i in 1:n) {
        u[i] <- theta(x[-i], ...)
        }
        uu <- mean(u) - u
        acc <- sum(uu * uu * uu)/(6 * (sum(uu * uu))^1.5)
        zalpha <- qnorm(alpha)
        tt <- pnorm(z0 + (z0 + zalpha)/(1 - acc * (z0 + zalpha)))
        ooo <- trunc(tt * nboot)
        if (ooo[1]>0) confpoints <- sort(thetastar)[ooo]
        else confpoints <- rep(NA, length(alpha))
        return(as.vector(c(confpoints, confpoints.percent)))
    }
}
#################

line.plots <- function(est, se, Ylabel, Xlab, yaxis=2, Xlim=NULL){
    if (is.null(Xlim)) Xlim <- range(c(est+2*se, est-2*se))
    n <- length(est)
    if(n != length(se))stop("lengths not match")
    plot(1:n, 1:n, xlim=Xlim, ylim=c(0.75, n+0.25),
         type="n", axes=F, xlab=Xlab, ylab="")
    axis(1)
    axis(yaxis, at=1:n, labels=Ylabel, las=1)
    segments(y0=1:n, y1=1:n, x0=est-2*se, x1=est+2*se)
    segments(y0=1:n, y1=1:n, x0=est-1*se, x1=est+1*se, lwd=2.5)
    points(est, 1:n)
    abline(v=0, col="gray")
    invisible()
}

line.plots.compare <- function(est1, se1, est2, se2, Ylabel, Xlab, yaxis=2, V=NULL){
    n <- length(est1)
    if(n != length(se1) | n !=length(se2) | n != length(est2) )stop("lengths not match")
    plot(1:n, 1:n, xlim=range(c(est1+2*se1, est1-2*se1, est2+2*se2, est2-2*se2)), ylim=c(0.75, n+0.25), type="n", axes=F, xlab=Xlab, ylab="")
    axis(1)
    axis(yaxis, at=1:n, labels=Ylabel, las=1)
    segments(y0=(1:n)-0.125, y1=(1:n)-0.125, x0=est1-2*se1, x1=est1+2*se1)
    segments(y0=(1:n)-0.125, y1=(1:n)-0.125, x0=est1-1*se1, x1=est1+1*se1, lwd=2.5)
    points(est1, (1:n)-0.125, pch=16, cex=0.5)

    segments(y0=(1:n)+0.125, y1=(1:n)+0.125, x0=est2-2*se2, x1=est2+2*se2, col="gray")
    segments(y0=(1:n)+0.125, y1=(1:n)+0.125, x0=est2-1*se2, x1=est2+1*se2, lwd=2.5, col="gray")
    points(est2, (1:n)+0.125, cex=0.5, col="gray")
    if(is.null(V))
        abline(v=0, col="gray")
    else abline(v=V, col="gray")
    invisible()
}

## power transformation
powerT <- function(y, lambda1=c(-1,-1/2,-1/4), lambda2 = c(1/4, 1/2, 1), layout1=2){
  nt <- length(lambda1)+length(lambda2)+1
  transformed <- cbind(outer(y,lambda1,"^"),log(y),(outer(y,lambda2,"^")))
  y.power <- data.frame(transformed=c(transformed),
                        lambda = factor(rep(round(c(lambda1,0,lambda2), 2),
                          rep(length(y),nt))))
  ans <- qqmath(~transformed | lambda,
                data=y.power,
                prepanel = prepanel.qqmathline,
                panel = function(x, ...) {
                  panel.grid(h = 0)
                  panel.qqmath(x, col=gray(0.5))
                  panel.qqmathline(x, distribution = qnorm)
                }, aspect=1, scale = list(y = "free"),
                layout=c(layout1,ceiling(nt/layout1)),
                xlab = "Unit Normal Quantile",
                ylab = "y")
  ans
}

